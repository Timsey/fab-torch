{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd25370",
   "metadata": {},
   "source": [
    "# Visualise AIS Many Well\n",
    "In this notebook we perform some visualisations of the annealed sampling algorithms performance, such as how AIS scales with the number of intermediate distributions for the Many Well problem with 32 dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb056a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57471d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from fab.sampling_methods import AnnealedImportanceSampler, Metropolis, HamiltoneanMonteCarlo\n",
    "from fab.utils.logging import ListLogger\n",
    "from fab import FABModel\n",
    "from fab.target_distributions import TargetDistribution\n",
    "from fab.target_distributions.many_well import ManyWellEnergy\n",
    "from examples.make_flow import make_wrapped_normflowdist\n",
    "from fab.utils.plotting import plot_history, plot_contours, plot_marginal_pair\n",
    "from fab.utils.numerical import effective_sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8585fc4c",
   "metadata": {},
   "source": [
    "## Setup Target Distribution & AIS based distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim: int = 32\n",
    "seed: int = 1\n",
    "n_flow_layers = 10\n",
    "layer_nodes_per_dim = 10\n",
    "torch.manual_seed(seed)\n",
    "batch_size = 1000\n",
    "plotting_bounds = (-3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb90972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup target\n",
    "target = ManyWellEnergy(dim, a=-0.5, b=-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cbf84e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setup flow spec\n",
    "flow = make_wrapped_normflowdist(dim, n_flow_layers=n_flow_layers,\n",
    "                                     layer_nodes_per_dim=layer_nodes_per_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed63bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intermediate_distributions = 4\n",
    "n_inner_steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9027d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup transition_operator spec\n",
    "transition_operator = HamiltoneanMonteCarlo(\n",
    "            n_ais_intermediate_distributions=n_intermediate_distributions,\n",
    "            n_outer=1,\n",
    "            epsilon=1.0, L=n_inner_steps, dim=dim,\n",
    "            step_tuning_method=\"p_accept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649dffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup full model\n",
    "fab_model = FABModel(flow=flow,\n",
    "                         target_distribution=target,\n",
    "                         n_intermediate_distributions=n_intermediate_distributions,\n",
    "                         transition_operator=transition_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model\n",
    "fab_model.load(\"models/many_well_32/model.pt\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(fab_model, n_samples: int = batch_size, dim: int = dim):\n",
    "    n_rows = dim // 2\n",
    "    fig, axs = plt.subplots(dim // 2, 2, sharex=True, sharey=True, figsize=(10, n_rows * 3))\n",
    "\n",
    "    samples_flow = fab_model.flow.sample((n_samples,))\n",
    "    samples_ais = fab_model.annealed_importance_sampler.sample_and_log_weights(n_samples,\n",
    "                                                                               logging=False)[0]\n",
    "\n",
    "    for i in range(n_rows):\n",
    "        plot_contours(target.log_prob_2D, bounds=plotting_bounds, ax=axs[i, 0])\n",
    "        plot_contours(target.log_prob_2D, bounds=plotting_bounds, ax=axs[i, 1])\n",
    "\n",
    "        # plot flow samples\n",
    "        plot_marginal_pair(samples_flow, ax=axs[i, 0], bounds=plotting_bounds,\n",
    "                           marginal_dims=(i * 2, i * 2 + 1))\n",
    "        axs[i, 0].set_xlabel(f\"dim {i * 2}\")\n",
    "        axs[i, 0].set_ylabel(f\"dim {i * 2 + 1}\")\n",
    "\n",
    "        # plot ais samples\n",
    "        plot_marginal_pair(samples_ais, ax=axs[i, 1], bounds=plotting_bounds,\n",
    "                           marginal_dims=(i * 2, i * 2 + 1))\n",
    "        axs[i, 1].set_xlabel(f\"dim {i * 2}\")\n",
    "        axs[i, 1].set_ylabel(f\"dim {i * 2 + 1}\")\n",
    "        plt.tight_layout()\n",
    "    axs[0, 1].set_title(\"ais samples\")\n",
    "    axs[0, 0].set_title(\"flow samples\")\n",
    "    return [fig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a911137",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(fab_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d51e35",
   "metadata": {},
   "source": [
    "## Now for varying number of AIS distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a5647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fab_model.annealed_importance_sampler.transition_operator.epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e761630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fab_model.annealed_importance_sampler.transition_operator.common_epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d408902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ais_dist = 5 \n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3b32a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_ais(n_ais_intermediate_distributions):\n",
    "    transition_operator = HamiltoneanMonteCarlo(\n",
    "        n_ais_intermediate_distributions=n_ais_intermediate_distributions,\n",
    "        n_outer=1,\n",
    "        epsilon=1.0, L=1, dim=dim,\n",
    "        step_tuning_method=\"p_accept\",\n",
    "        eval_mode=True)\n",
    "    transition_operator.common_epsilon = torch.ones_like(transition_operator.common_epsilon) * 0.0065 # from trained HMC\n",
    "    transition_operator.epsilons = torch.ones_like(transition_operator.epsilons) * 0.15\n",
    "    base_dist = fab_model.flow\n",
    "    ais = AnnealedImportanceSampler(base_distribution=base_dist,\n",
    "                                    target_log_prob=target.log_prob,\n",
    "                                    transition_operator=transition_operator,\n",
    "                                    n_intermediate_distributions=n_ais_intermediate_distributions,\n",
    "                                    )\n",
    "    return ais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ais = setup_ais(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc6212",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, log_w = ais.sample_and_log_weights(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c82972",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_contours(target.log_prob_2D, ax=ax, bounds=[-3, 3], n_contour_levels=50)\n",
    "plot_marginal_pair(samples, ax=ax, bounds=[-3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87d9290",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(log_w.detach().numpy(), density=True, alpha=0.75, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc20770",
   "metadata": {},
   "source": [
    "## Visualise the effect of the number of AIS distributions\n",
    "We see that as the number of AIS distributions increases, the effective sample size increases, and the variance in the importance log weights decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3171c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_distributions = [1, 2, 4, 8, 16, 32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af279c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = ListLogger()\n",
    "log_weight_hist = [] # listlogger is meant for scalars so we store the log weight history separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3909e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ess_hist = []\n",
    "for n_ais_dist in tqdm(range_n_distributions):\n",
    "    # turn off step size tuning, initial step size is reasonable and we only want to visualise the effect of \n",
    "    # the number of ais distributions. \n",
    "    ais = setup_ais(n_ais_dist)\n",
    "    ais.transition_operator.set_eval_mode(True) \n",
    "    base_samples, base_log_w, ais_samples, ais_log_w = \\\n",
    "        ais.generate_eval_data(50*batch_size, batch_size)\n",
    "    base_samples, base_log_w, ais_samples, ais_log_w = base_samples.detach(), base_log_w.detach(), ais_samples.detach(), ais_log_w.detach() \n",
    "    info = {\"eval_ess_ais\": effective_sample_size(log_w=ais_log_w, normalised=False).item(),\n",
    "           \"log_w_var\": torch.var(ais_log_w).item()}\n",
    "    logger.write(info)\n",
    "    log_weight_hist.append(ais_log_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f94ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "axs[0].plot(range_n_distributions, logger.history[\"eval_ess_ais\"])\n",
    "axs[0].set_ylabel(\"effective sample size\")\n",
    "axs[0].set_xlabel(\"number of intermediate ais distributions\")\n",
    "\n",
    "axs[1].plot(range_n_distributions, logger.history[\"log_w_var\"])\n",
    "axs[1].set_ylabel(\"var log w\")\n",
    "axs[1].set_xlabel(\"number of intermediate ais distributions\")\n",
    "axs[1].set_yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ea02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.history['log_w_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eefd88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at samples after a the max number of AIS steps. \n",
    "fig, axs = plt.subplots(1, figsize=(15, 5))\n",
    "plot_contours(target.log_prob_2D, ax=axs, bounds=[-3, 3], n_contour_levels=50)\n",
    "plot_marginal_pair(ais_samples[:1000], ax=axs, bounds=[-3, 3])\n",
    "axs.set_title(\"samples (ais) vs target contours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb8e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and for comparison with only a few intermediate distributions\n",
    "n_ais_dist = 1 # change this number to see how the number of distributions effects the samples from AIS.\n",
    "ais_2_dist = setup_ais(n_ais_dist)\n",
    "\n",
    "fig, axs = plt.subplots(1, figsize=(15, 5))\n",
    "plot_contours(target.log_prob_2D, ax=axs, bounds=[-3, 3], n_contour_levels=50)\n",
    "plot_marginal_pair(ais_2_dist.sample_and_log_weights(1000)[0], ax=axs, bounds=[-30, 30])\n",
    "axs.set_title(\"samples (ais) vs target contours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893a36b5",
   "metadata": {},
   "source": [
    "Plot log weight distribution for a relatively low number of AIS distributions vs a high number of AIS distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c767274",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_n_low = 0\n",
    "print(f\"plotting log_w for {range_n_distributions[iter_n_low]} AIS distributions for first 100 samples\")\n",
    "log_w_low = log_weight_hist[iter_n_low][:1000].numpy()\n",
    "n, bins, patches = plt.hist(log_w_low, density=True, alpha=0.75, bins=40, color=\"green\", \n",
    "                            label=f\"{range_n_distributions[iter_n_low]} ais dist\")\n",
    "\n",
    "iter_n_high = -1\n",
    "print(f\"plotting log_w for {range_n_distributions[iter_n_high]} AIS distributions for first 100 samples\")\n",
    "log_w_high = log_weight_hist[iter_n_high][:1000].numpy()\n",
    "n, bins, patches = plt.hist(log_w_high, density=True, alpha=0.75, bins=40, color=\"blue\", \n",
    "                            label=f\"{range_n_distributions[iter_n_high]} ais dist\")\n",
    "\n",
    "plt.xscale(\"symlog\") # use log x scale so we can see both on the same plot\n",
    "plt.legend()\n",
    "plt.xlabel(\"log_w\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c06b4",
   "metadata": {},
   "source": [
    "The same but dropping very low values for the log weights so we don't need to log the x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd7ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_w_low = log_weight_hist[iter_n_low]\n",
    "log_w_low = log_w_low[log_w_low > -10][:1000].numpy()\n",
    "n, bins, patches = plt.hist(log_w_low, density=True, alpha=0.75, bins=40, color=\"green\", \n",
    "                            label=f\"{range_n_distributions[iter_n_low]} ais dist\")\n",
    "\n",
    "log_w_high = log_weight_hist[iter_n_high]\n",
    "log_w_high = log_w_high[log_w_high > -10][:1000].numpy()\n",
    "n, bins, patches = plt.hist(log_w_high, density=True, alpha=0.75, bins=40, color=\"blue\", \n",
    "                            label=f\"{range_n_distributions[iter_n_high]} ais dist\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"log_w\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba19c9c",
   "metadata": {},
   "source": [
    "# Visualise sample changes within a long chain\n",
    "Useful to toggle with / without loaded model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e4ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(n_ais_dist, batch_size = 64):\n",
    "    ais = setup_ais(n_ais_dist)\n",
    "    target_minus_base_hist = []\n",
    "    \n",
    "    \n",
    "    # Initialise AIS with samples from the base distribution.\n",
    "    x, log_prob_p0 = ais.base_distribution.sample_and_log_prob((batch_size,))\n",
    "    x, log_prob_p0 = ais._remove_nan_and_infs(x, log_prob_p0, descriptor=\"chain init\")\n",
    "    target_minus_base = ais.target_log_prob(x) - ais.base_distribution.log_prob(x)\n",
    "    target_minus_base_hist.append(np.asarray(target_minus_base.detach()))\n",
    "\n",
    "    log_w = ais.intermediate_unnormalised_log_prob(x, 1) - log_prob_p0\n",
    "    # Move through sequence of intermediate distributions via MCMC.\n",
    "    for j in range(1, ais.n_intermediate_distributions+1):\n",
    "        x, log_w = ais.perform_transition(x, log_w, j)\n",
    "        target_minus_base = ais.target_log_prob(x) - ais.base_distribution.log_prob(x)\n",
    "        target_minus_base_hist.append(np.asarray(target_minus_base.detach()))\n",
    "    \n",
    "    return target_minus_base_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda602c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_minus_base_hist = run(n_ais_dist=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca93dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.asarray(target_minus_base_hist), \"ob\", alpha=0.05)\n",
    "plt.ylabel(\"log prob target - log prob base\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c00c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}