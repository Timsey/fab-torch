defaults:
  - override hydra/launcher: joblib

target:
  dim: 2
  loc_scaling: 40
  n_mixes: 40
  log_var_scaling: 1.0

flow:
  layer_nodes_per_dim: 40
  n_layers: 15
  act_norm: false
  use_snf: false


fab:
  loss_type: forward_kl
  transition_operator:
    type: metropolis
    n_inner_steps: 1
    tune_step_size: false
    target_p_accept: 0.65
    init_step_size: 5.0
  n_intermediate_distributions: 2


training:
  checkpoint_load_dir: null
  tlimit: null
  seed: 0
  lr: 1e-4
  batch_size: 128
  n_iterations: null
  n_flow_forward_pass: 10_000_000
  use_gpu: true
  use_64_bit: true
  use_buffer: false # below config fields are all for use_buffer = True
  prioritised_buffer: false
  n_batches_buffer_sampling: 4
  buffer_temp: 1.0 # rate that we weight new experience over old
  maximum_buffer_length: 12800
  min_buffer_length: 1280 # heuristic: set this to n_batches_buffer_sampling*batch_size*10
  log_w_clip_frac: null # null for no clipping, for non-prioritised replay
  max_grad_norm: 100.0 # null for no clipping
  w_adjust_max_clip: null # clipping of weight adjustment factor for prioritised replay


evaluation:
  n_plots: 20 # number of times we visualise the model throughout training.
  n_eval: 20 # for calculating metrics of flow w.r.t target.
  eval_batch_size: 512 # must be a multiple of inner batch size
  n_checkpoints: 10 # number of model checkpoints saved
  save_path:  ./results/gmm/seed${training.seed}/

logger:
  pandas_logger:
    save_period: 100 # how often to save the pandas dataframe as a csv
#  wandb:
#    name: GMM_${fab.loss_type}
#    project: fab
#    entity: flow-ais-bootstrap
#    tags: [alpha_2_loss]
