# Config file specifying the setup of a Boltzmann Generator
defaults:
  - _self_
  - node: desktop

hydra:
  run:
    dir: ${node.output_dir}/SoluteInWater/MD_training/${now:%Y-%m-%d}/${now:%H-%M-%S_%f} # Default Hydra output dir: all run output will be stored in subfolders of this.
  job:
    chdir: true

target:                               # Properties of molecular system
  solvent: water
  dim: 27  # 18  45                             # System dimension: 3 * (3 + 3 * num_solvent_molecules) for water in water (xyz).
  temperature: 300                    # Double, temperature of the system
  energy_cut: 1.e+8                   # Double, energy level at which regularization shall be applied
  energy_max: 1.e+20                  # Double, maximum level at which energies will be clamped
  n_threads: 18  # 1                       # Int, number of threads to be used, number of cores if null
  solute_pdb_path: null                                               # Filepath to solvent pdb
  solute_inpcrd_path: ${node.data_dir}/molecules/solutes/so2.inpcrd   # Filepath to solvent inpcrd
  solute_prmtop_path: ${node.data_dir}/molecules/solutes/so2.prmtop   # Filepath to solvent prmtop
  # Filepaths to load samples from
  train_samples_path: ${node.data_dir}/molecules/md/so2InWater_dim${target.dim}_temp${target.temperature}_eq1000_burn100000_steps10000_every10_ecTrue_ichbonds_rwTrue.h5
  val_samples_path: ${node.data_dir}/molecules/md/so2InWater_dim${target.dim}_temp${target.temperature}_eq1000_burn100000_steps10000_every10_ecTrue_ichbonds_rwTrue.h5
  test_samples_path: null
  # NOTE: Do these have to match the MD data, or do we want to generate MD data with best practices (with H2O constraints), and compute energy without constraints?
  external_constraints: true          # Whether to use external force constraints for keeping the system in place.
  internal_constraints: "none"        # Internal constraints to use. E.g. "hbonds" (restricts hydrogen atom bond lengths) or "none".
  rigidwater: false                   # Whether to use rigid water molecules: regardless of internal constraints, OpenMM will use fully rigid water molecules by default (bond length and angles).

flow:                                  # Properties of the flow model
  solvent_flow: true                   # Bool, flag whether to use the flow model used for aldp in the fab paper
  use_snf: false                      # Bool, flag whether to use Stochastic Flow
  resampled_base: false               # Bool, flag whether to use resampled base distribution
  type: circ-coup-nsf  # circ-coup-nsf                 # String, type of the flow: "circ-coup-nsf", "circ-ar-nsf"
  base:
    type: gauss-uni  # gauss-uni
    params: null
    learn_mean_var: false             # Bool, flag whether to learn mean and variance of base distribution.
  blocks: 12  #12                          # Int, number of Real NVP blocks, consisting of an ActNorm layer
  blocks_per_layer: 1                 # Int, number of blocks per layer
  hidden_units: 256  # 256                 # Int, number of hidden units of the NN in neural spline layers
  num_bins: 8 # 8, 9                         # Int, number of bins of the neural splines
  init_identity: True                 # Bool, flag whether to initialize layers as identity map
  dropout: 0.                         # Float, dropout probability for the NN layers
                                      # For below: if specified, a permutation, and a affine coupling layer
  circ_shift: random  # constant, random                  # String, whether to shift circular coordinates, can be none, constant, or random
  actnorm: False                      # Bool, flag whether to include an ActNorm layers
  mixing: null                        # String, how features are mixed


fab:
  loss_type: forward_kl               # Whether to use AIS, and type of loss for AIS. If not AIS, rest of args are only used for potential eval.
  use_ais: false                      # Whether to use AIS for evaluation still
  n_intermediate_distributions: 8     # Int, number of intermediate distributions
  alpha: 2.0
  transition_operator:
    type: hmc
    n_inner_steps: 4
    init_step_size: 0.05              # original eps = 0.1 / 2
    tune_step_size: true              # Bool, flag whether to adjust step size for Metropolis
    target_p_accept: 0.65


training:                             # Properties of the training procedure
  seed: 0                             # Int, seed to be used for the random number generator
  num_workers: 4  # 4                 # Int, number of workers to be used for data loading
  checkpoint_load_dir: null           # Checkpoint dir to load from if continuing training
  n_iterations: 5000  #50000                 # Int, maximum number of iteration
  n_flow_forward_pass: null
  batch_size: 1024               # Int, batch size used during training
  tlimit: null                        # Int, time limit of run in seconds
  use_gpu: true
  use_64_bit: true
  lr: 5.e-4                           # Double, learning rate
  wd: 1.e-5                           # Double, regularization parameter
  optimizer: adam                     # String, name of the optimizer
  lr_scheduler:
    type: cosine                      # String, kind of LR scheduler, can be exponential, cosine
  warmup_iter: null                   # Int, number of iterations used for warmup
  max_grad_norm: 1.e3                 # Double, limit for gradient clipping
  # Buffer args
  use_buffer: false  # true                 # Buffer args follow below here
  prioritised_buffer: false  #true          # If True then FAB loss WILL be used no matter what fab.loss_type is.


evaluation:
  eval_mode: "val"                    # String, mode of evaluation, can be "val" or "test"
  print_eval: true                    # Bool, flag whether to print evaluation results to stdout.
  plot_MD_energies: false             # Bool, flag whether to plot MD energies as a sanity check.
  n_plots: 50                         # number of times we visualise the model throughout training.
  n_eval: 500  # ${training.n_iterations}  # 20                          # for calculating metrics of flow w.r.t target.
  eval_batch_size: 1024               # For AIS-type evaluation, must be a multiple of inner batch size (`batch_size`)
  n_checkpoints: 10                   # number of model checkpoints saved


logger:
#  wandb:
#    name: ${fab.loss_type}_dim${target.dim}_iter${training.n_iterations}
#    project: SO2_in_H2O
#    entity: timsey
  pandas_logger:
    save_period: 100                  # how often to save the pandas dataframe as a csv